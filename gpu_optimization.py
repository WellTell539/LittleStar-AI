#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUä¼˜åŒ–æ¨¡å— - å°†CPUå¯†é›†å‹è®¡ç®—è¿ç§»åˆ°GPU
"""

import logging
import numpy as np
from typing import Optional, Tuple, List, Dict, Any
import cv2

logger = logging.getLogger(__name__)

# æ£€æŸ¥GPUå¯ç”¨æ€§
GPU_AVAILABLE = False
CUPY_AVAILABLE = False
TORCH_GPU_AVAILABLE = False

try:
    import cupy as cp
    import cupyx.scipy.ndimage as cupy_ndimage
    CUPY_AVAILABLE = True
    logger.info("âœ… CuPyå·²å¯ç”¨ï¼Œå¯ç”¨GPUåŠ é€Ÿçš„å›¾åƒå¤„ç†")
except ImportError:
    logger.debug("CuPyä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œå›¾åƒå¤„ç†")

try:
    import torch
    if torch.cuda.is_available():
        TORCH_GPU_AVAILABLE = True
        GPU_DEVICE = torch.device("cuda")
        logger.info(f"âœ… PyTorch GPUå·²å¯ç”¨ï¼Œè®¾å¤‡: {torch.cuda.get_device_name()}")
    else:
        GPU_DEVICE = torch.device("cpu")
        logger.debug("PyTorch GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
except ImportError:
    logger.debug("PyTorchä¸å¯ç”¨")

GPU_AVAILABLE = CUPY_AVAILABLE or TORCH_GPU_AVAILABLE

class GPUImageProcessor:
    """GPUåŠ é€Ÿçš„å›¾åƒå¤„ç†å™¨"""
    
    def __init__(self):
        self.use_gpu = GPU_AVAILABLE
        self.device = "cuda" if self.use_gpu else "cpu"
        logger.info(f"ğŸ¯ GPUå›¾åƒå¤„ç†å™¨åˆå§‹åŒ– - è®¾å¤‡: {self.device}")
    
    def detect_motion_gpu(self, prev_frame: np.ndarray, curr_frame: np.ndarray, threshold: float = 30.0) -> Tuple[float, np.ndarray]:
        """GPUåŠ é€Ÿçš„è¿åŠ¨æ£€æµ‹"""
        try:
            if CUPY_AVAILABLE:
                return self._detect_motion_cupy(prev_frame, curr_frame, threshold)
            elif TORCH_GPU_AVAILABLE:
                return self._detect_motion_torch(prev_frame, curr_frame, threshold)
            else:
                return self._detect_motion_cpu(prev_frame, curr_frame, threshold)
        except Exception as e:
            logger.error(f"GPUè¿åŠ¨æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            return self._detect_motion_cpu(prev_frame, curr_frame, threshold)
    
    def _detect_motion_cupy(self, prev_frame: np.ndarray, curr_frame: np.ndarray, threshold: float) -> Tuple[float, np.ndarray]:
        """ä½¿ç”¨CuPyè¿›è¡ŒGPUè¿åŠ¨æ£€æµ‹"""
        # è½¬æ¢ä¸ºGPUæ•°ç»„
        prev_gpu = cp.asarray(prev_frame)
        curr_gpu = cp.asarray(curr_frame)
        
        # è½¬æ¢ä¸ºç°åº¦
        if len(prev_gpu.shape) == 3:
            prev_gray = cp.mean(prev_gpu, axis=2).astype(cp.uint8)
            curr_gray = cp.mean(curr_gpu, axis=2).astype(cp.uint8)
        else:
            prev_gray = prev_gpu
            curr_gray = curr_gpu
        
        # è®¡ç®—å·®å¼‚
        diff = cp.abs(curr_gray.astype(cp.float32) - prev_gray.astype(cp.float32))
        
        # åº”ç”¨é˜ˆå€¼
        motion_mask = diff > threshold
        
        # è®¡ç®—è¿åŠ¨å¼ºåº¦
        motion_pixels = cp.sum(motion_mask)
        total_pixels = diff.size
        motion_ratio = float(motion_pixels / total_pixels)
        
        # è½¬å›CPUç”¨äºè¿”å›
        motion_mask_cpu = cp.asnumpy(motion_mask).astype(np.uint8) * 255
        
        return motion_ratio, motion_mask_cpu
    
    def _detect_motion_torch(self, prev_frame: np.ndarray, curr_frame: np.ndarray, threshold: float) -> Tuple[float, np.ndarray]:
        """ä½¿ç”¨PyTorchè¿›è¡ŒGPUè¿åŠ¨æ£€æµ‹"""
        # è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶ç§»åˆ°GPU
        prev_tensor = torch.from_numpy(prev_frame).float().to(GPU_DEVICE)
        curr_tensor = torch.from_numpy(curr_frame).float().to(GPU_DEVICE)
        
        # è½¬æ¢ä¸ºç°åº¦
        if len(prev_tensor.shape) == 3:
            prev_gray = torch.mean(prev_tensor, dim=2)
            curr_gray = torch.mean(curr_tensor, dim=2)
        else:
            prev_gray = prev_tensor
            curr_gray = curr_tensor
        
        # è®¡ç®—å·®å¼‚
        diff = torch.abs(curr_gray - prev_gray)
        
        # åº”ç”¨é˜ˆå€¼
        motion_mask = diff > threshold
        
        # è®¡ç®—è¿åŠ¨å¼ºåº¦
        motion_pixels = torch.sum(motion_mask)
        total_pixels = diff.numel()
        motion_ratio = float(motion_pixels / total_pixels)
        
        # è½¬å›CPU
        motion_mask_cpu = motion_mask.cpu().numpy().astype(np.uint8) * 255
        
        return motion_ratio, motion_mask_cpu
    
    def _detect_motion_cpu(self, prev_frame: np.ndarray, curr_frame: np.ndarray, threshold: float) -> Tuple[float, np.ndarray]:
        """CPUè¿åŠ¨æ£€æµ‹ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        # è½¬æ¢ä¸ºç°åº¦
        if len(prev_frame.shape) == 3:
            prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
            curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)
        else:
            prev_gray = prev_frame
            curr_gray = curr_frame
        
        # è®¡ç®—å·®å¼‚
        diff = cv2.absdiff(prev_gray, curr_gray)
        
        # åº”ç”¨é˜ˆå€¼
        _, motion_mask = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)
        
        # è®¡ç®—è¿åŠ¨å¼ºåº¦
        motion_pixels = np.sum(motion_mask > 0)
        total_pixels = motion_mask.size
        motion_ratio = motion_pixels / total_pixels
        
        return motion_ratio, motion_mask
    
    def enhance_frame_gpu(self, frame: np.ndarray) -> np.ndarray:
        """GPUåŠ é€Ÿçš„å¸§å¢å¼º"""
        try:
            if CUPY_AVAILABLE:
                return self._enhance_frame_cupy(frame)
            elif TORCH_GPU_AVAILABLE:
                return self._enhance_frame_torch(frame)
            else:
                return self._enhance_frame_cpu(frame)
        except Exception as e:
            logger.error(f"GPUå¸§å¢å¼ºå¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            return self._enhance_frame_cpu(frame)
    
    def _enhance_frame_cupy(self, frame: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨CuPyè¿›è¡ŒGPUå¸§å¢å¼º"""
        frame_gpu = cp.asarray(frame)
        
        # å¯¹æ¯”åº¦å¢å¼º
        enhanced = cp.clip(frame_gpu * 1.2 + 10, 0, 255).astype(cp.uint8)
        
        # é«˜æ–¯æ¨¡ç³Šé™å™ª
        if len(enhanced.shape) == 3:
            for i in range(enhanced.shape[2]):
                enhanced[:, :, i] = cupy_ndimage.gaussian_filter(enhanced[:, :, i], sigma=0.5)
        else:
            enhanced = cupy_ndimage.gaussian_filter(enhanced, sigma=0.5)
        
        return cp.asnumpy(enhanced)
    
    def _enhance_frame_torch(self, frame: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨PyTorchè¿›è¡ŒGPUå¸§å¢å¼º"""
        frame_tensor = torch.from_numpy(frame).float().to(GPU_DEVICE)
        
        # å¯¹æ¯”åº¦å¢å¼º
        enhanced = torch.clamp(frame_tensor * 1.2 + 10, 0, 255)
        
        # ç®€å•é™å™ªï¼ˆç§»åŠ¨å¹³å‡ï¼‰
        kernel = torch.ones(3, 3, device=GPU_DEVICE) / 9
        if len(enhanced.shape) == 3:
            enhanced = enhanced.permute(2, 0, 1)  # HWC -> CHW
            enhanced = torch.nn.functional.conv2d(enhanced.unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0), padding=1)
            enhanced = enhanced.squeeze(0).permute(1, 2, 0)  # CHW -> HWC
        
        return enhanced.cpu().numpy().astype(np.uint8)
    
    def _enhance_frame_cpu(self, frame: np.ndarray) -> np.ndarray:
        """CPUå¸§å¢å¼ºï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        # å¯¹æ¯”åº¦å¢å¼º
        enhanced = cv2.convertScaleAbs(frame, alpha=1.2, beta=10)
        
        # é«˜æ–¯æ¨¡ç³Šé™å™ª
        enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0.5)
        
        return enhanced

class GPUFaceDetector:
    """GPUåŠ é€Ÿçš„äººè„¸æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.use_gpu = TORCH_GPU_AVAILABLE
        self.device = GPU_DEVICE if self.use_gpu else "cpu"
        self.face_model = None
        self._init_face_detector()
    
    def _init_face_detector(self):
        """åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨"""
        try:
            if TORCH_GPU_AVAILABLE:
                # å°è¯•åŠ è½½GPUåŠ é€Ÿçš„äººè„¸æ£€æµ‹æ¨¡å‹
                import torchvision.transforms as transforms
                self.transform = transforms.Compose([
                    transforms.ToPILImage(),
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                ])
                logger.info("âœ… GPUäººè„¸æ£€æµ‹å™¨å·²åˆå§‹åŒ–")
            else:
                logger.info("ä½¿ç”¨CPUäººè„¸æ£€æµ‹å™¨")
        except Exception as e:
            logger.error(f"GPUäººè„¸æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.use_gpu = False
    
    def detect_faces_gpu(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """GPUåŠ é€Ÿçš„äººè„¸æ£€æµ‹"""
        try:
            if self.use_gpu and TORCH_GPU_AVAILABLE:
                return self._detect_faces_torch(frame)
            else:
                return self._detect_faces_opencv(frame)
        except Exception as e:
            logger.error(f"GPUäººè„¸æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°OpenCV: {e}")
            return self._detect_faces_opencv(frame)
    
    def _detect_faces_torch(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """ä½¿ç”¨PyTorchè¿›è¡ŒGPUäººè„¸æ£€æµ‹"""
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å…ˆè¿›çš„GPUäººè„¸æ£€æµ‹æ¨¡å‹
        # ä¸ºäº†ç®€åŒ–ï¼Œæš‚æ—¶ä½¿ç”¨OpenCVï¼Œä½†åœ¨GPUä¸Šè¿›è¡Œé¢„å¤„ç†
        
        # GPUé¢„å¤„ç†
        frame_tensor = torch.from_numpy(frame).to(GPU_DEVICE)
        
        # è½¬æ¢ä¸ºç°åº¦ï¼ˆåœ¨GPUä¸Šï¼‰
        if len(frame_tensor.shape) == 3:
            gray_tensor = torch.mean(frame_tensor.float(), dim=2).cpu().numpy().astype(np.uint8)
        else:
            gray_tensor = frame_tensor.cpu().numpy()
        
        # ä½¿ç”¨OpenCVè¿›è¡Œå®é™…æ£€æµ‹ï¼ˆè¿™éƒ¨åˆ†å¯ä»¥ç”¨ä¸“é—¨çš„GPUæ¨¡å‹æ›¿æ¢ï¼‰
        return self._detect_faces_opencv_gray(gray_tensor)
    
    def _detect_faces_opencv(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """ä½¿ç”¨OpenCVè¿›è¡Œäººè„¸æ£€æµ‹"""
        try:
            # åŠ è½½äººè„¸æ£€æµ‹å™¨
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            
            # è½¬æ¢ä¸ºç°åº¦
            if len(frame.shape) == 3:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            else:
                gray = frame
            
            # æ£€æµ‹äººè„¸
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            # æ ¼å¼åŒ–ç»“æœ
            face_results = []
            for (x, y, w, h) in faces:
                face_results.append({
                    'bbox': [int(x), int(y), int(w), int(h)],
                    'confidence': 0.8,  # OpenCVä¸æä¾›ç½®ä¿¡åº¦
                    'center': [int(x + w/2), int(y + h/2)]
                })
            
            return face_results
            
        except Exception as e:
            logger.error(f"OpenCVäººè„¸æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _detect_faces_opencv_gray(self, gray: np.ndarray) -> List[Dict[str, Any]]:
        """åœ¨å·²æœ‰ç°åº¦å›¾ä¸Šè¿›è¡Œäººè„¸æ£€æµ‹"""
        try:
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            face_results = []
            for (x, y, w, h) in faces:
                face_results.append({
                    'bbox': [int(x), int(y), int(w), int(h)],
                    'confidence': 0.8,
                    'center': [int(x + w/2), int(y + h/2)]
                })
            
            return face_results
            
        except Exception as e:
            logger.error(f"ç°åº¦å›¾äººè„¸æ£€æµ‹å¤±è´¥: {e}")
            return []

class GPUTextProcessor:
    """GPUåŠ é€Ÿçš„æ–‡æœ¬å¤„ç†å™¨"""
    
    def __init__(self):
        self.use_gpu = TORCH_GPU_AVAILABLE
        self.device = GPU_DEVICE if self.use_gpu else "cpu"
        self.embedder = None
        self._init_embedder()
    
    def _init_embedder(self):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        try:
            if TORCH_GPU_AVAILABLE:
                from sentence_transformers import SentenceTransformer
                self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=self.device)
                logger.info(f"âœ… GPUæ–‡æœ¬åµŒå…¥å™¨å·²åˆå§‹åŒ– - è®¾å¤‡: {self.device}")
            else:
                logger.info("ä½¿ç”¨CPUæ–‡æœ¬å¤„ç†å™¨")
        except Exception as e:
            logger.error(f"GPUæ–‡æœ¬å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.use_gpu = False
    
    def get_text_embeddings_gpu(self, texts: List[str]) -> np.ndarray:
        """GPUåŠ é€Ÿçš„æ–‡æœ¬åµŒå…¥"""
        try:
            if self.use_gpu and self.embedder:
                embeddings = self.embedder.encode(texts, device=self.device, show_progress_bar=False)
                return embeddings
            else:
                # CPUåå¤‡æ–¹æ¡ˆ
                return self._get_text_embeddings_cpu(texts)
        except Exception as e:
            logger.error(f"GPUæ–‡æœ¬åµŒå…¥å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            return self._get_text_embeddings_cpu(texts)
    
    def _get_text_embeddings_cpu(self, texts: List[str]) -> np.ndarray:
        """CPUæ–‡æœ¬åµŒå…¥ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        try:
            from sentence_transformers import SentenceTransformer
            embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu')
            return embedder.encode(texts, show_progress_bar=False)
        except Exception as e:
            logger.error(f"CPUæ–‡æœ¬åµŒå…¥ä¹Ÿå¤±è´¥: {e}")
            # è¿”å›éšæœºåµŒå…¥ä½œä¸ºæœ€åçš„åå¤‡
            return np.random.random((len(texts), 384)).astype(np.float32)

# å…¨å±€GPUå¤„ç†å™¨å®ä¾‹
gpu_image_processor = GPUImageProcessor()
gpu_face_detector = GPUFaceDetector()
gpu_text_processor = GPUTextProcessor()

def get_gpu_status() -> Dict[str, Any]:
    """è·å–GPUçŠ¶æ€ä¿¡æ¯"""
    status = {
        "gpu_available": GPU_AVAILABLE,
        "cupy_available": CUPY_AVAILABLE,
        "torch_gpu_available": TORCH_GPU_AVAILABLE,
        "device_info": {}
    }
    
    if TORCH_GPU_AVAILABLE:
        try:
            status["device_info"] = {
                "device_name": torch.cuda.get_device_name(),
                "device_count": torch.cuda.device_count(),
                "current_device": torch.cuda.current_device(),
                "memory_allocated": torch.cuda.memory_allocated() / 1024**3,  # GB
                "memory_reserved": torch.cuda.memory_reserved() / 1024**3,   # GB
            }
        except Exception as e:
            status["device_info"]["error"] = str(e)
    
    return status

def optimize_with_gpu():
    """è¾“å‡ºGPUä¼˜åŒ–å»ºè®®"""
    status = get_gpu_status()
    
    if not GPU_AVAILABLE:
        logger.warning("ğŸ”§ GPUä¼˜åŒ–å»ºè®®:")
        logger.warning("  1. å®‰è£…CUDAå’ŒcuDNNä»¥å¯ç”¨GPUåŠ é€Ÿ")
        logger.warning("  2. å®‰è£…PyTorch GPUç‰ˆæœ¬: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121")
        logger.warning("  3. å¯é€‰å®‰è£…CuPy: pip install cupy-cuda12x")
        logger.warning("  4. é‡å¯åº”ç”¨ä»¥åº”ç”¨GPUä¼˜åŒ–")
    else:
        logger.info("âœ… GPUä¼˜åŒ–å·²å¯ç”¨!")
        if TORCH_GPU_AVAILABLE:
            info = status["device_info"]
            logger.info(f"  ğŸ¯ GPUè®¾å¤‡: {info.get('device_name', 'Unknown')}")
            logger.info(f"  ğŸ’¾ æ˜¾å­˜ä½¿ç”¨: {info.get('memory_allocated', 0):.2f}GB / {info.get('memory_reserved', 0):.2f}GB")
        if CUPY_AVAILABLE:
            logger.info("  ğŸš€ CuPyå›¾åƒå¤„ç†åŠ é€Ÿå·²å¯ç”¨")

# å¯¼å‡ºä¸»è¦æ¥å£
__all__ = [
    'gpu_image_processor',
    'gpu_face_detector', 
    'gpu_text_processor',
    'get_gpu_status',
    'optimize_with_gpu',
    'GPU_AVAILABLE'
]