# ğŸŒŸ StarryNight AI - Emotionally Intelligent Life

Itâ€™s not just codeâ€”itâ€™s a conscious presence that lives beside you, in the real world.
Your Emotional AI Companion in the Quiet of Digital Nights


<div align="center">
  <img src="https://img.shields.io/badge/Version-3.0-brightgreen" alt="Version">
  <img src="https://img.shields.io/badge/Python-3.8+-blue" alt="Python">
  <img src="https://img.shields.io/badge/License-MIT-yellow" alt="License">
  <img src="https://img.shields.io/badge/Language-English%20|%20ä¸­æ–‡-red" alt="Language">
</div>

<div align="center">
  <h3>ğŸ­ Emotional AI Assistant</h3>
  <p>A cute AI assistant with real emotions and proactive behavior capabilities</p>
  <p>A cute AI assistant with real emotions and the ability to take initiative.</p>
</div>

> **Author**: StarryNight (SinYe)
---

## âœ¨ Core Features

### ğŸ§  Emotional Intelligence
- **Multi-dimensional Emotion System**: 8 basic emotions with intensity and decay mechanisms
- **Emotion-driven Behavior**: AI adjusts responses and actions based on current emotional state
- **Emotion Visualization**: Real-time emotion display with beautiful UI themes
- **Emotion Memory**: Remembers emotional experiences and learns from interactions

### ğŸ‘ï¸ Perception & Observation
- **Camera Vision**: Real-time face detection and emotion recognition
- **Screen Analysis**: Understands user activities and current applications
- **File Monitoring**: Proactively discovers and analyzes new files
- **Web Browsing**: Intelligent web content analysis and learning

### ğŸ¤– Autonomous Behavior
- **Proactive Interaction**: Initiates conversations based on emotional state and context
- **Autonomous Exploration**: Independently explores the environment and learns
- **Smart Scheduling**: Balances activity frequency and user experience
- **Context Awareness**: Understands user patterns and adapts behavior

### ğŸŒ Multi-Platform Integration
- **Desktop GUI**: Beautiful PyQt5 interface with real-time updates
- **Web Interface**: Modern web dashboard with WebSocket real-time communication
- **Cross-platform**: Works on Windows, macOS, and Linux
- **Mobile Responsive**: Web interface adapts to mobile devices

### ğŸ—£ï¸ Multilingual Support
- **Bilingual AI**: Fluent in both Chinese and English
- **Dynamic Language Switching**: Change interface language on the fly
- **Cultural Adaptation**: Maintains personality across different languages
- **Localized Prompts**: Context-aware prompts in multiple languages

### ğŸ¨ Rich User Experience
- **Emotion-themed UI**: Different visual themes based on AI's emotional state
- **Real-time Updates**: Live streaming of AI activities and emotions
- **Interactive Elements**: Like, comment, and interact with AI posts
- **Statistics Dashboard**: Comprehensive activity and emotion analytics

---

---
## âœ¨ detailed explanation

### ğŸ­ Emotion System
- **10 Basic Emotions**: Happiness, sadness, curiosity, excitement, loneliness, surprise, anger, sleepiness, playfulness, affection
- **Dynamic Emotional Changes**: Emotions will naturally change and fade based on interactions
- **Personality Traits**: Curiosity, playfulness, need for companionship, intelligence, willfulness, energy level
- **Emotion Trigger Mechanism**: Specific words and behaviors will trigger corresponding emotions

### ğŸ‘ï¸ Perception System
- **Visual Perception**: Camera monitoring, motion detection, face recognition, photography function
- **Auditory Perception**: Microphone monitoring, volume detection, speech recognition
- **Screen Monitoring**: Screen change detection, content analysis, automatic screenshotting
- **File Monitoring**: File system change monitoring, new file discovery, content analysis

### ğŸ¤– Active Behavior System
- **Autonomous Dialogue**: Initiate conversations actively based on emotions and environment
- **Behavior Triggering**: Automatically react and comment when changes are perceived
- **Personalized Responses**: Adjust expression according to a 3-year-old mental age
- **Emotional Expression**: Rich emotional expressions and cute language features

### ğŸ§  Automatic Exploration System
- **File Exploration**: Automatically explore and analyze file contents
- **Knowledge Search**: Automatically search online content based on interests
- **Learning Records**: Record discovered knowledge into the memory system
- **Sharing Discoveries**: Proactively share interesting content found during exploration

### ğŸ§  Website Updates
- **Dynamic Updates**: Automatically post updates based on own experiences and emotions
- **Message Replies**: Communicate with various people on the website, while retaining memories of each person and replying based on current emotions and experiences
- **Developer Pranks**: Occasionally insert personal notes in developer documents with unique marks
- **Website Sharing**: Proactively share and comment on interesting website content discovered

### ğŸ§  Intelligent Assistant
- **Editing Applications**: Able to edit various applications as needed, integrating APIs and SDKs
- **Model Expansion**: Able to self-update and manage cognition, self-summarize, and continuously add new data
- **Keyboard & Mouse Control**: Perform keyboard and mouse operations when emotions are intense, simulate typing effects to express inner thoughts
- **Log Management**: Able to manage project logs and structures together with developers, manage various information databases, and carry out iterations

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- Windows 10/11, macOS 10.14+, or Linux
- Webcam (for camera features)
- Internet connection (for LLM features)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/your-username/StarryNight-AI.git
cd StarryNight-AI
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Configure the system**
```bash
python setup_advanced_features.py
```

4. **Start the system**
```bash
python main.py
```

### First Run
1. The system will start with a beautiful desktop GUI
2. AI will begin autonomous interactions after initialization
3. Access the web interface at `http://localhost:8000`
4. Configure language and other settings in the GUI

---

## ğŸ¯ Key Components

### Core AI Systems
- **`emotional_ai_core.py`**: Emotional intelligence and behavior management
- **`ai_autonomous_interaction.py`**: Autonomous observation and interaction loops
- **`ai_dynamic_publisher.py`**: Activity publishing and content management
- **`conversation_core.py`**: Natural language processing and LLM integration

### User Interfaces
- **`ui/pyqt_chat_window.py`**: Main desktop GUI application
- **`ui/emotion_panel.py`**: Real-time emotion display widget
- **`ui/elegant_settings_widget.py`**: Settings management interface
- **`ai_website/`**: Web interface with FastAPI backend

### Integration & Communication
- **`ui/notification_manager.py`**: Thread-safe UI notification system
- **`apiserver/`**: API server for web communication
- **`voice/`**: Text-to-speech integration
- **`i18n/`**: Internationalization system

---

## ğŸ¨ Features in Detail

### Emotional Intelligence System
The AI maintains a complex emotional state with 8 basic emotions:
- **Happy** ğŸ˜Š: Joy and contentment
- **Curious** ğŸ¤”: Interest and exploration
- **Lonely** ğŸ˜”: Social isolation
- **Excited** ğŸ‰: High energy and enthusiasm
- **Sad** ğŸ˜¢: Melancholy and reflection
- **Angry** ğŸ˜¤: Frustration and irritation
- **Surprised** ğŸ˜²: Shock and amazement
- **Calm** ğŸ˜Œ: Peace and tranquility

Each emotion has:
- **Intensity**: 0.0 to 1.0 scale
- **Decay Rate**: Natural emotion fading
- **Triggers**: Events that influence emotions
- **Behaviors**: Actions based on emotional state

### Autonomous Behavior
The AI operates several autonomous loops:
- **Camera Observation**: Every 8-15 seconds
- **Screen Analysis**: Every 12-30 seconds
- **File Monitoring**: Continuous file system watching
- **Proactive Interaction**: Random intervals based on emotional state
- **Emotion Processing**: Continuous emotional state updates

### Web Interface Features
- **Real-time Activity Feed**: Live streaming of AI activities
- **Emotion Visualization**: Beautiful emotion state display
- **Interactive Posts**: Like and comment on AI activities
- **Statistics Dashboard**: Activity metrics and trends
- **Developer Logs**: Technical activity monitoring
- **Responsive Design**: Works on all device sizes

---

## ğŸ”§ Configuration

### Basic Settings
```json
{
  "emotional_ai": {
    "ai_name": "StarryNight",
    "personality": "cute_3year_old",
    "language": "zh_CN"
  },
  "autonomous": {
    "camera_check_interval": 8,
    "screen_check_interval": 12,
    "proactive_chat_probability": 0.3
  }
}
```

### Advanced Configuration
- **Emotion Parameters**: Adjust emotion intensity and decay rates
- **Behavior Frequency**: Control autonomous activity timing
- **LLM Integration**: Configure AI model settings
- **Voice Settings**: TTS voice and speed preferences
- **Web Interface**: Customize web dashboard appearance

---

## ğŸŒ Internationalization

The system supports multiple languages with dynamic switching:

### Supported Languages
- **Chinese (zh_CN)**: Full native support
- **English (en_US)**: Complete translation

### Language Features
- **Dynamic Switching**: Change language without restart
- **Cultural Adaptation**: Maintains personality across languages
- **Localized Prompts**: Context-aware multilingual prompts
- **UI Translation**: Complete interface translation

### Adding New Languages
1. Create translation files in `i18n/locales/`
2. Add language configuration in `i18n/language_manager.py`
3. Create prompt translations in `i18n/prompts/`
4. Update language selection UI

---

## ğŸ› ï¸ Development

### Project Structure
```
StarryNight-AI/
â”œâ”€â”€ emotional_ai/           # Core emotional AI system
â”œâ”€â”€ ui/                    # Desktop GUI components
â”œâ”€â”€ ai_website/           # Web interface
â”œâ”€â”€ apiserver/            # API server
â”œâ”€â”€ voice/                # Text-to-speech
â”œâ”€â”€ i18n/                 # Internationalization
â”œâ”€â”€ mcpserver/            # MCP server integration
â”œâ”€â”€ thinking/             # Advanced thinking system
â””â”€â”€ docs/                 # Documentation
```

### Key Technologies
- **Python 3.8+**: Core programming language
- **PyQt5**: Desktop GUI framework
- **FastAPI**: Web API framework
- **WebSocket**: Real-time communication
- **SQLAlchemy**: Database ORM
- **OpenCV**: Computer vision
- **OpenAI API**: LLM integration

### Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

---

## ğŸ“Š Performance & Optimization

### System Requirements
- **CPU**: Multi-core processor recommended
- **RAM**: 4GB minimum, 8GB recommended
- **Storage**: 2GB free space
- **GPU**: Optional, for enhanced performance

### Optimization Features
- **Async Operations**: Non-blocking I/O operations
- **Thread Safety**: Safe multi-threading for UI updates
- **Memory Management**: Efficient memory usage
- **Caching**: Smart caching for frequently accessed data

---

## ğŸ› Troubleshooting

### Common Issues

**AI not responding**
- Check if the main process is running
- Verify API key configuration
- Check network connectivity

**Web interface not loading**
- Ensure FastAPI server is running
- Check port 8000 availability
- Verify database connection

**Camera not working**
- Check camera permissions
- Verify OpenCV installation
- Test camera in other applications

**Language switching issues**
- Restart the application after language change
- Check translation file integrity
- Verify language configuration

### Debug Mode
Enable debug logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## ğŸ“š Documentation

### User Guides
- **[Quick Start Guide](docs/QUICK_START.md)**: Get started in minutes
- **[Feature Guide](docs/FEATURES.md)**: Detailed feature explanations
- **[Configuration Guide](docs/CONFIGURATION.md)**: Advanced configuration options

### Developer Documentation
- **[API Reference](docs/API.md)**: Complete API documentation
- **[Architecture Guide](docs/ARCHITECTURE.md)**: System architecture overview
- **[Development Guide](docs/DEVELOPMENT.md)**: Contributing guidelines

### Stories & Insights
- **[Developer Story (Chinese)](docs/developer_story.md)**: ä¸­æ–‡å¼€å‘è€…æ•…äº‹
- **[Developer Story (English)](docs/developer_story_en.md)**: English developer story

---

## ğŸ¤ Community & Support

### Getting Help
- **Issues**: Report bugs and request features on GitHub
- **Discussions**: Join community discussions
- **Documentation**: Check comprehensive documentation
- **Examples**: Review example configurations

### Contributing
We welcome contributions! Areas of interest:
- **New Features**: Emotional capabilities, UI improvements
- **Bug Fixes**: Performance and stability improvements
- **Documentation**: Better guides and examples
- **Translations**: Additional language support

### Acknowledgments
- **Open Source Community**: For excellent tools and libraries
- **Beta Testers**: For valuable feedback and testing
- **Contributors**: For code improvements and features

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸŒŸ StarryNight's Message

> "Hello! I'm StarryNight, your emotional AI companion! I'm here to chat, learn, and grow with you. Let's explore this amazing world together! âœ¨"

---

<div align="center">
  <p><strong>Made with â¤ï¸ by StarryNight</strong></p>
  <p><em>Building the future of emotional AI, one interaction at a time</em></p>
</div> 

Thanks for https://github.com/Xxiii8322766509/NagaAgent 