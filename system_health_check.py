#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»Ÿå¥åº·æ£€æŸ¥è„šæœ¬ - éªŒè¯æ‰€æœ‰ç»„ä»¶æ˜¯å¦å°±ç»ª
"""

import sys
import importlib
import subprocess
from typing import Dict, List, Tuple

def check_module(module_name: str, display_name: str = None) -> Tuple[bool, str]:
    """æ£€æŸ¥å•ä¸ªæ¨¡å—"""
    display_name = display_name or module_name
    try:
        importlib.import_module(module_name)
        return True, f"âœ… {display_name} - å·²å®‰è£…"
    except ImportError as e:
        return False, f"âŒ {display_name} - æœªå®‰è£… ({e})"

def check_gpu_support() -> Dict[str, any]:
    """æ£€æŸ¥GPUæ”¯æŒ"""
    gpu_info = {
        "cuda_available": False,
        "cupy_available": False,
        "device_info": {}
    }
    
    try:
        import torch
        gpu_info["cuda_available"] = torch.cuda.is_available()
        if gpu_info["cuda_available"]:
            gpu_info["device_info"] = {
                "device_name": torch.cuda.get_device_name(),
                "device_count": torch.cuda.device_count(),
                "memory_allocated": f"{torch.cuda.memory_allocated() / 1024**3:.2f}GB",
                "memory_reserved": f"{torch.cuda.memory_reserved() / 1024**3:.2f}GB"
            }
    except Exception as e:
        gpu_info["torch_error"] = str(e)
    
    try:
        import cupy
        gpu_info["cupy_available"] = True
    except ImportError:
        gpu_info["cupy_available"] = False
    
    return gpu_info

def main():
    """ä¸»æ£€æŸ¥å‡½æ•°"""
    print("ğŸ” StarryNightAIç³»ç»Ÿ - å¥åº·æ£€æŸ¥")
    print("=" * 60)
    
    # æ ¸å¿ƒä¾èµ–æ£€æŸ¥
    core_modules = [
        ("fastapi", "FastAPI Webæ¡†æ¶"),
        ("uvicorn", "ASGIæœåŠ¡å™¨"),
        ("sqlalchemy", "æ•°æ®åº“ORM"),
        ("bcrypt", "å¯†ç åŠ å¯†"),
        ("jose", "JWTå¤„ç†"),
        ("aiohttp", "å¼‚æ­¥HTTPå®¢æˆ·ç«¯"),
        ("transformers", "Transformeræ¨¡å‹"),
        ("sentence_transformers", "å¥å­åµŒå…¥æ¨¡å‹"),
        ("torch", "PyTorchæ·±åº¦å­¦ä¹ "),
        ("opencv", "è®¡ç®—æœºè§†è§‰"),
        ("pygame", "éŸ³é¢‘æ’­æ”¾"),
        ("PyQt5", "GUIæ¡†æ¶"),
    ]
    
    print("\nğŸ“¦ æ ¸å¿ƒä¾èµ–æ£€æŸ¥:")
    all_core_good = True
    for module, name in core_modules:
        success, message = check_module(module, name)
        print(f"  {message}")
        if not success:
            all_core_good = False
    
    # å¯é€‰ä¾èµ–æ£€æŸ¥
    optional_modules = [
        ("cupy", "CuPy GPUåŠ é€Ÿ"),
        ("torchvision", "PyTorchè§†è§‰"),
        ("torchaudio", "PyTorchéŸ³é¢‘"),
        ("speechrecognition", "è¯­éŸ³è¯†åˆ«"),
        ("tweepy", "Twitter API"),
        ("py2neo", "Neo4jå›¾æ•°æ®åº“"),
        ("sounddevice", "éŸ³é¢‘è®¾å¤‡"),
        ("playwright", "æµè§ˆå™¨è‡ªåŠ¨åŒ–"),
    ]
    
    print("\nğŸ”§ å¯é€‰ä¾èµ–æ£€æŸ¥:")
    for module, name in optional_modules:
        success, message = check_module(module, name)
        print(f"  {message}")
    
    # GPUæ”¯æŒæ£€æŸ¥
    print("\nğŸ¯ GPUæ”¯æŒæ£€æŸ¥:")
    gpu_info = check_gpu_support()
    
    if gpu_info["cuda_available"]:
        print("  âœ… CUDA GPUæ”¯æŒ - å·²å¯ç”¨")
        device_info = gpu_info["device_info"]
        print(f"    ğŸ“± è®¾å¤‡: {device_info.get('device_name', 'Unknown')}")
        print(f"    ğŸ”¢ æ•°é‡: {device_info.get('device_count', 0)}")
        print(f"    ğŸ’¾ æ˜¾å­˜: {device_info.get('memory_allocated', '0GB')} / {device_info.get('memory_reserved', '0GB')}")
    else:
        print("  âš ï¸ CUDA GPUæ”¯æŒ - æœªæ£€æµ‹åˆ°æˆ–æœªå¯ç”¨")
    
    if gpu_info["cupy_available"]:
        print("  âœ… CuPy GPUåŠ é€Ÿ - å·²å®‰è£…")
    else:
        print("  âš ï¸ CuPy GPUåŠ é€Ÿ - æœªå®‰è£…")
    
    # é…ç½®æ–‡ä»¶æ£€æŸ¥
    print("\nğŸ“„ é…ç½®æ–‡ä»¶æ£€æŸ¥:")
    try:
        from config import config
        print("  âœ… config.json - å·²åŠ è½½")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        if config.api.api_key:
            print("  âœ… APIå¯†é’¥ - å·²é…ç½®")
        else:
            print("  âš ï¸ APIå¯†é’¥ - æœªé…ç½®")
        
        if config.api_server.enabled:
            print("  âœ… APIæœåŠ¡å™¨ - å·²å¯ç”¨")
        else:
            print("  âš ï¸ APIæœåŠ¡å™¨ - å·²ç¦ç”¨")
            
    except Exception as e:
        print(f"  âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    if all_core_good:
        print("ğŸ‰ ç³»ç»Ÿæ£€æŸ¥å®Œæˆ!")
        print("\nğŸ“‹ å¯åŠ¨å»ºè®®:")
        print("1. è¿è¡Œä¸»ç¨‹åº: python main.py")
        print("2. è¿è¡Œå®Œæ•´ç³»ç»Ÿ: python start_complete_fixed_system.py")
        print("3. è®¿é—®AIç½‘ç«™: http://127.0.0.1:8080")
        
        if gpu_info["cuda_available"]:
            print("\nğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨ï¼Œæ¨ç†æ€§èƒ½å°†å¤§å¹…æå‡!")
        else:
            print("\nğŸ’¡ GPUä¼˜åŒ–å»ºè®®:")
            print("- å®‰è£…NVIDIA GPUé©±åŠ¨å’ŒCUDA")
            print("- é‡å¯åº”ç”¨ä»¥æ£€æµ‹GPU")
    else:
        print("âš ï¸ å‘ç°ç¼ºå¤±ä¾èµ–ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("python install_all_dependencies.py")

if __name__ == "__main__":
    main()